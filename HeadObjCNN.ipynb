{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTu3ksUDe9lk",
        "outputId": "073d7646-d494-4ad4-eb00-0b448e8dd1ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N7PQGCULwpB",
        "outputId": "075e7f99-9ec0-4f93-f288-a246d800f49a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX\n",
        "!pip install --quiet pytorch-lightning>=1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "0kQA6NX5hKog"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import collections\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer, seed_everything\n",
        "from pytorch_lightning.loggers.csv_logs import CSVLogger\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import sys\n",
        "from tensorboardX import SummaryWriter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "import numpy as np\n",
        "import time\n",
        "import shutil\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "import os\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "from math import floor\n",
        "from math import ceil\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YzgfkQFIfLmz",
        "outputId": "dcbcdc40-8dd8-463f-9969-5b2bfd6c59fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/gaze_project'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "os.chdir('/content/gdrive/MyDrive/gaze_project')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "VADlJTHKXM7H"
      },
      "outputs": [],
      "source": [
        "# create dataset\n",
        "class MyDataset(data.Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        feature, target = self.features[index], self.labels[index]\n",
        "        return feature, target\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    \n",
        "# load data.    \n",
        "def LoadData(dataset_dir, batch_size):\n",
        "\n",
        "    print(\"\\nLoading the training dataset\")\n",
        "    trainingX = torch.from_numpy(np.load(dataset_dir + 'trainingX.npy')).float()\n",
        "    trainingY = torch.from_numpy(np.load(dataset_dir + 'trainingY.npy')).float()    \n",
        "    print('\\nTraining Data Size: {}'.format(list(trainingX.size())))\n",
        "\n",
        "    train_dataset = MyDataset(trainingX, trainingY)\n",
        "\n",
        "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=8, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    print(\"\\nLoading the testing dataset\")\n",
        "    testX = torch.from_numpy(np.load(dataset_dir + 'testX.npy')).float()\n",
        "    testY = torch.from_numpy(np.load(dataset_dir + 'testY.npy')).float()\n",
        "\n",
        "    test_size = testX.size()\n",
        "    test_new_size = test_size[0]//2\n",
        "\n",
        "    test_X = testX[0:test_new_size, :]\n",
        "    test_Y = testY[0:test_new_size, :]\n",
        "\n",
        "    print('\\nTest Data Size: {}'.format(list(test_X.size())))\n",
        "    test_dataset = MyDataset(test_X, test_Y)\n",
        "\n",
        "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=8, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    print(\"\\nLoading the validation dataset\")\n",
        "    validationX = testX[test_new_size:, :]\n",
        "    validationY = testY[test_new_size:, :]\n",
        "\n",
        "    print('\\nValidation Data Size: {}'.format(list(validationX.size())))\n",
        "    validation_dataset = MyDataset(validationX, validationY)\n",
        "\n",
        "    validation_loader = data.DataLoader(dataset=validation_dataset, num_workers=8, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader, validation_loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CosineWarmupScheduler(torch.optim.lr_scheduler._LRScheduler):\n",
        "    \n",
        "    def __init__(self, optimizer, warm_up, max_iters):\n",
        "        self.warm_up = warm_up\n",
        "        self.max_n_iters = max_iters\n",
        "        super().__init__(optimizer)\n",
        "        \n",
        "    def get_lr(self):\n",
        "        lr_factor = self.get_lr_factor(epoch=self.last_epoch)\n",
        "        return [base_lr * lr_factor for base_lr in self.base_lrs]\n",
        "    \n",
        "    def get_lr_factor(self, epoch):\n",
        "        lr_factor = 0.5 * (1 + np.cos(np.pi * epoch / self.max_n_iters))\n",
        "        if epoch <= self.warm_up:\n",
        "            lr_factor *= epoch * 1.0 / self.warm_up\n",
        "        return lr_factor"
      ],
      "metadata": {
        "id": "BI-el1c3COsf"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "lrvoab8LHsI5"
      },
      "outputs": [],
      "source": [
        "class HeadObjCNN(pl.LightningModule):\n",
        "    def __init__(self, \n",
        "                 input_size, \n",
        "                 seq_length, \n",
        "                 seq_feature_num, \n",
        "                 n_output, \n",
        "                 lr, \n",
        "                 warm_up,\n",
        "                 max_iters,\n",
        "                 criterion, \n",
        "                 dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        # model params\n",
        "        self.input_size = input_size\n",
        "        self.lr = lr\n",
        "        self.n_output = n_output\n",
        "        self.warm_up = warm_up\n",
        "\n",
        "        self.max_iters = max_iters\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.criterion = criterion\n",
        "\n",
        "        self.seq_length = seq_length\n",
        "        self.seq_feature_num = seq_feature_num\n",
        "        self.seq_size = self.seq_length * self.seq_feature_num\n",
        "\n",
        "        # the model params\n",
        "        cnn_1d_out = 128\n",
        "        cnn_1d_pooling_rate = 2\n",
        "        cnn_1d_kernal_size = 2\n",
        "        self.cnn_1d_output_size = floor((self.seq_length - cnn_1d_kernal_size + 1)/cnn_1d_pooling_rate)* cnn_1d_out\n",
        "\n",
        "        prd_fc_linear_size_1 = 128\n",
        "        prd_fc_linear_size_2 = 128\n",
        "\n",
        "        self.cnn_1d = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=self.seq_feature_num, out_channels=cnn_1d_out,kernel_size=cnn_1d_kernal_size),\n",
        "            nn.BatchNorm1d(cnn_1d_out),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(cnn_1d_pooling_rate),\n",
        "            nn.Dropout(p = self.dropout),\n",
        "             )\n",
        "        \n",
        "        self.prd_fc = nn.Sequential(\n",
        "            nn.Linear(self.cnn_1d_output_size, prd_fc_linear_size_2),\n",
        "            nn.BatchNorm1d(prd_fc_linear_size_1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = self.dropout),\n",
        "            nn.Linear(prd_fc_linear_size_2, self.n_output)\n",
        "             ) \n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        head_object_seq = x[:, 0:self.seq_size]       \n",
        "        \n",
        "        head_object_seq = head_object_seq.reshape(-1, self.seq_length, self.seq_feature_num)\n",
        "        head_object_seq = head_object_seq.permute(0,2,1)\n",
        "        seq_out = self.cnn_1d(head_object_seq)\n",
        "        seq_out = seq_out.reshape(-1, self.cnn_1d_output_size)\n",
        "        gaze = self.prd_fc(seq_out)\n",
        "        return gaze\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "\n",
        "        lr_scheduler = CosineWarmupScheduler(optimizer, \n",
        "                                             warm_up=self.warm_up, \n",
        "                                             max_iters=self.max_iters)\n",
        "        return [optimizer], [{'scheduler': lr_scheduler, 'interval': 'step'}]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        features, labels = batch\n",
        "\n",
        "        features = features.reshape(-1, self.input_size).to(device)\n",
        "        labels = labels.reshape(-1, self.n_output).to(device)\n",
        "\n",
        "        output = self(features)\n",
        "\n",
        "        loss = self.criterion(output, labels)\n",
        "\n",
        "        self.log('train_loss', loss)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        features, labels = batch\n",
        "\n",
        "        features = features.reshape(-1, self.input_size).to(device)\n",
        "        labels = labels.reshape(-1, self.n_output).to(device)\n",
        "\n",
        "        output = self(features)\n",
        "\n",
        "        loss = self.criterion(output, labels)\n",
        "\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "\n",
        "        features, labels = batch\n",
        "\n",
        "        features = features.reshape(-1, self.input_size).to(device)\n",
        "        labels = labels.reshape(-1, self.n_output).to(device)\n",
        "\n",
        "        output = self(features)\n",
        "\n",
        "        loss = self.criterion(output, labels)\n",
        "\n",
        "        prd_error = 0\n",
        "        ver_error = 0\n",
        "        hor_error = 0\n",
        "\n",
        "        for i in range(output.size(0)):\n",
        "            prd_error += CalAngularDist(labels[i, 0:2], output[i, 0:2])\n",
        "            ver_error += abs(labels[i, 0] - output[i, 0])\n",
        "            hor_error += abs(labels[i, 1] - output[i, 1])\n",
        "\n",
        "        mean_ver_error = ver_error / output.size(0)\n",
        "        mean_hor_error = hor_error / output.size(0)\n",
        "        mean_prd_error = prd_error / output.size(0)\n",
        "\n",
        "        pixel_pred = AngularCoord2PixelCoord(output[0])\n",
        "        pixel_gth = AngularCoord2PixelCoord(labels[0])\n",
        "\n",
        "        prd_x.append(pixel_pred[0])\n",
        "        prd_y.append(pixel_pred[1])\n",
        "        gth_x.append(pixel_gth[0])\n",
        "        gth_y.append(pixel_gth[1])\n",
        "\n",
        "        self.log(\"test_loss\", loss, prog_bar=True)\n",
        "        self.log(\"test_ang_error\", mean_prd_error, prog_bar=True)\n",
        "        self.log(\"mean_ver_error\", mean_ver_error, prog_bar=True)\n",
        "        self.log(\"mean_hor_error\", mean_hor_error, prog_bar=True)\n",
        "\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NYEoBygevAc4"
      },
      "outputs": [],
      "source": [
        "def get_args(train=True):\n",
        "    args = dict()\n",
        "    args['feature_num'] = 1702\n",
        "    args['seq_length'] = 50\n",
        "    args['seq_feature_num'] = 11\n",
        "    # the dropout rate of the model.\n",
        "    args['dropout_rate'] = 0.5   \n",
        "    # the directory that saves the dataset.\n",
        "    args['dataset_dir'] = 'DGaze_TrainTest/'\n",
        "    # the number of total epochs to run\n",
        "    args['epochs'] = 30\n",
        "    # the batch size\n",
        "    args['batch_size'] = 64\n",
        "    # the initial learning rate.\n",
        "    args['lr'] = 1e-2\n",
        "    args['warm_up'] = 2\n",
        "    return args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "s43FWxvFLoAS"
      },
      "outputs": [],
      "source": [
        "\n",
        "def CalAngularDist(gth, prd):\n",
        "\n",
        "\tvertical_fov = math.pi*110/180;\n",
        "\n",
        "\tscreen_w = 1080\n",
        "\tscreen_h = 1200\n",
        "\tscreen_center_x = 0.5*screen_w\n",
        "\tscreen_center_y = 0.5*screen_h\n",
        "\n",
        "\tscreen_dist = 0.5* screen_h/math.tan(vertical_fov/2)\n",
        "\t\n",
        "\n",
        "\tgth = AngularCoord2ScreenCoord(gth)\n",
        "\tprd = AngularCoord2ScreenCoord(prd)\n",
        "\n",
        "\tgth[0] = gth[0]*screen_w\n",
        "\tgth[1] = gth[1]*screen_h\n",
        "\tprd[0] = prd[0]*screen_w\n",
        "\tprd[1] = prd[1]*screen_h\n",
        "\t\n",
        "\t#the distance between eye and gth.\n",
        "\teye2gth = np.sqrt(np.square(screen_dist) + np.square(gth[0] - screen_center_x) + np.square(gth[1] - screen_center_y))\n",
        "\t#the distance between eye and prd.\n",
        "\teye2prd = np.sqrt(np.square(screen_dist) + np.square(prd[0] - screen_center_x) + np.square(prd[1] - screen_center_y))\n",
        "\t#the distance between gth and prd.\n",
        "\tgth2prd = np.sqrt(np.square(prd[0] - gth[0]) + np.square(prd[1] - gth[1]))\n",
        "\t\n",
        "\t#the angular distance between gth and prd.\n",
        "\tangular_dist = 180/math.pi*math.acos((np.square(eye2gth) + np.square(eye2prd) - np.square(gth2prd))/(2*eye2gth*eye2prd))\n",
        "\treturn angular_dist\n",
        "\n",
        "def AngularCoord2PixelCoord(angular_coord):\n",
        "\tscreen_w = 1080\n",
        "\tscreen_h = 1200\n",
        "\n",
        "\tscreen_coord = AngularCoord2ScreenCoord(angular_coord);\n",
        "\n",
        "\tpixel_coord = np.zeros(2)\n",
        "\n",
        "\tpixel_coord[0] = screen_coord[0]*screen_w\n",
        "\tpixel_coord[1] = screen_coord[1]*screen_h\n",
        "\n",
        "\treturn pixel_coord\n",
        "\t\n",
        "def AngularCoord2ScreenCoord(angular_coord):\n",
        "\n",
        "\tvertical_fov = math.pi*110/180\n",
        "\n",
        "\tscreen_w = 1080\n",
        "\tscreen_h = 1200\n",
        "\n",
        "\tscreen_dist = 0.5* screen_h/math.tan(vertical_fov/2)\n",
        "\t\n",
        "\tscreen_coord = np.zeros(2)\n",
        "\n",
        "\tscreen_coord[0] = (screen_dist * math.tan(math.pi*angular_coord[0] / 180) + 0.5*screen_w) / screen_w\n",
        "\n",
        "\tscreen_coord[1] = (screen_dist * math.tan(-math.pi*angular_coord[1] / 180) + 0.5*screen_h) / screen_h\n",
        "\treturn screen_coord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "JVVbRfJku18W"
      },
      "outputs": [],
      "source": [
        "def main(args, train=True):\n",
        "\n",
        "    # Load dataset\n",
        "    train_loader, test_loader, validation_loader = LoadData(args['dataset_dir'], args['batch_size'])\n",
        "\n",
        "    # Create the model.\n",
        "    root_dir = os.getcwd()\n",
        "\n",
        "    print('\\n==> Starting...')\n",
        "\n",
        "    csv_logger = CSVLogger('./', name='head_cnn', version='1'),\n",
        "\n",
        "    trainer = Trainer(\n",
        "        default_root_dir=root_dir,\n",
        "        max_epochs=args['epochs'],\n",
        "        logger=csv_logger,\n",
        "        gpus=1,\n",
        "        log_every_n_steps=1,\n",
        "        progress_bar_refresh_rate=1\n",
        "    )\n",
        "\n",
        "    model = HeadObjCNN(\n",
        "        input_size = args['feature_num'], \n",
        "        seq_length = args['seq_length'], \n",
        "        seq_feature_num = args['seq_feature_num'], \n",
        "        n_output = 2, \n",
        "        lr = args['lr'], \n",
        "        warm_up = args['warm_up'],\n",
        "        max_iters = args['epochs'],\n",
        "        criterion = nn.L1Loss(), \n",
        "        dropout = args['dropout_rate']\n",
        "    )\n",
        "\n",
        "    if train:\n",
        "      print('\\n==> Training...')\n",
        "      trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=validation_loader)\n",
        "\n",
        "      metrics = pd.read_csv('./head_cnn/0/metrics.csv')\n",
        "      train_loss = metrics[['train_loss', 'step', 'epoch']][~np.isnan(metrics['train_loss'])]\n",
        "      val_loss = metrics[['val_loss', 'epoch']][~np.isnan(metrics['val_loss'])]\n",
        "\n",
        "      fig, axes = plt.subplots(1, 2, figsize=(16, 5), dpi=100)\n",
        "      axes[0].set_title('Train loss per batch')\n",
        "      axes[0].plot(train_loss['step'][::2000], train_loss['train_loss'][::2000])\n",
        "      axes[1].set_title('Validation loss per epoch')\n",
        "      axes[1].plot(val_loss['epoch'], val_loss['val_loss'], color='orange')\n",
        "      plt.show(block = True)\n",
        "\n",
        "      print(f\"Train loss: {train_loss['train_loss'].iloc[-1]:.3f}\")\n",
        "      print(f\"Val loss:   {val_loss['val_loss'].iloc[-1]:.3f}\")\n",
        "\n",
        "    else:\n",
        "\n",
        "\n",
        "      print('\\n==> Testing...')\n",
        "      chk_path = \"./head_cnn/0/checkpoints/epoch=6-step=114373.ckpt\"\n",
        "      model2 = model.load_from_checkpoint(chk_path,         \n",
        "                                          input_size = args['feature_num'], \n",
        "                                          seq_length = args['seq_length'], \n",
        "                                          seq_feature_num = args['seq_feature_num'], \n",
        "                                          n_output = 2, \n",
        "                                          lr = args['lr'], \n",
        "                                          warm_up = args['warm_up'],\n",
        "                                          max_iters = args['epochs'],\n",
        "                                          criterion = nn.L1Loss(), \n",
        "                                          dropout = args['dropout_rate'])\n",
        "      trainer.test(model=model2, dataloaders=test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plotComparisonGraph(gth_x, gth_y, prd_x, prd_y):\n",
        "  s = [5] * len(prd_x)\n",
        "  plt.figure(figsize=(12,9))\n",
        "\n",
        "  gth = plt.scatter(gth_x, gth_y, s, color = '#88c999')\n",
        "\n",
        "  prd = plt.scatter(prd_x, prd_y, s, color = 'hotpink')\n",
        "  plt.xlim(0, 1080)\n",
        "  plt.ylim(0, 1200)\n",
        "\n",
        "  plt.title(\"Predicted gaze positions versus ground truth\", fontsize=16)\n",
        "\n",
        "  plt.xlabel(\"Horizontal /pixel\", fontsize=16)\n",
        "  plt.ylabel(\"Vertical /pixel\", fontsize=16)\n",
        "\n",
        "  plt.legend((prd, gth),\n",
        "            ('Predicted', 'Ground Truth'),\n",
        "            scatterpoints=1,\n",
        "            loc='lower left',\n",
        "            ncol=3,\n",
        "            fontsize=12)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "I22EfadxaYjN"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8t6cJJklvTW",
        "outputId": "83e6f032-6b1c-4d57-9dd6-335b8c5d9145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "\n",
            "Loading the training dataset\n"
          ]
        }
      ],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# set the random seed to ensure reproducibility\n",
        "seed_everything(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "train = True\n",
        "\n",
        "prd_x = []\n",
        "prd_y = []\n",
        "gth_x = []\n",
        "gth_y = []\n",
        "\n",
        "args = get_args()\n",
        "main(args, train)\n",
        "\n",
        "if not train:\n",
        "  plotComparisonGraph(gth_x, gth_y, prd_x, prd_y)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "HeadObjCNN.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}