{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTu3ksUDe9lk",
        "outputId": "0983a4ee-db66-415b-8d71-3b2deae00021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N7PQGCULwpB",
        "outputId": "be918340-cd0a-4da0-d466-ef0c94883561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX\n",
        "!pip install --quiet pytorch-lightning>=1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0kQA6NX5hKog"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import collections\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer, seed_everything\n",
        "from pytorch_lightning.loggers.csv_logs import CSVLogger\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import sys\n",
        "from tensorboardX import SummaryWriter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "import numpy as np\n",
        "import time\n",
        "import shutil\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "import os\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "from math import floor\n",
        "from math import ceil\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "YzgfkQFIfLmz",
        "outputId": "0fb77cba-6039-489b-f826-c04b8b03879e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/gaze_project'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "os.chdir('/content/gdrive/MyDrive/gaze_project')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VADlJTHKXM7H"
      },
      "outputs": [],
      "source": [
        "# create dataset\n",
        "class MyDataset(data.Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        feature, target = self.features[index], self.labels[index]\n",
        "        return feature, target\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    \n",
        "# load data.    \n",
        "def LoadData(dataset_dir, batch_size):\n",
        "\n",
        "    print(\"\\nLoading the training dataset\")\n",
        "    trainingX = torch.from_numpy(np.load(dataset_dir + 'trainingX.npy')).float()\n",
        "    trainingY = torch.from_numpy(np.load(dataset_dir + 'trainingY.npy')).float()    \n",
        "    print('\\nTraining Data Size: {}'.format(list(trainingX.size())))\n",
        "\n",
        "    train_dataset = MyDataset(trainingX, trainingY)\n",
        "\n",
        "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=8, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    print(\"\\nLoading the testing dataset\")\n",
        "    testX = torch.from_numpy(np.load(dataset_dir + 'testX.npy')).float()\n",
        "    testY = torch.from_numpy(np.load(dataset_dir + 'testY.npy')).float()\n",
        "\n",
        "    test_size = testX.size()\n",
        "    test_new_size = test_size[0]//2\n",
        "\n",
        "    test_X = testX[0:test_new_size, :]\n",
        "    test_Y = testY[0:test_new_size, :]\n",
        "\n",
        "    print('\\nTest Data Size: {}'.format(list(test_X.size())))\n",
        "    test_dataset = MyDataset(test_X, test_Y)\n",
        "\n",
        "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=8, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    print(\"\\nLoading the validation dataset\")\n",
        "    validationX = testX[test_new_size:, :]\n",
        "    validationY = testY[test_new_size:, :]\n",
        "\n",
        "    print('\\nValidation Data Size: {}'.format(list(validationX.size())))\n",
        "    validation_dataset = MyDataset(validationX, validationY)\n",
        "\n",
        "    validation_loader = data.DataLoader(dataset=validation_dataset, num_workers=8, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader, validation_loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    d_k = q.size()[-1]\n",
        "    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n",
        "    attn_logits = attn_logits / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n",
        "    attention = F.softmax(attn_logits, dim=-1)\n",
        "    values = torch.matmul(attention, v)\n",
        "    return values, attention\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, embed_dim, n_heads):\n",
        "        super().__init__()\n",
        "        assert embed_dim % n_heads == 0, \"Embedding dimension must be 0 modulo number of heads.\"\n",
        "        \n",
        "        self.embed_dim = embed_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = embed_dim // n_heads\n",
        "        \n",
        "        self.qkv_proj = nn.Linear(input_dim, 3*embed_dim)\n",
        "        self.o_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        \n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.qkv_proj.weight)\n",
        "        self.qkv_proj.bias.data.fill_(0)\n",
        "        nn.init.xavier_uniform_(self.o_proj.weight)\n",
        "        self.o_proj.bias.data.fill_(0)\n",
        "\n",
        "    def forward(self, x, mask=None, return_attention=False):\n",
        "        batch_size, seq_length, embed_dim = x.size()\n",
        "        qkv = self.qkv_proj(x)\n",
        "        \n",
        "        qkv = qkv.reshape(batch_size, seq_length, self.n_heads, 3*self.head_dim)\n",
        "        qkv = qkv.permute(0, 2, 1, 3) # [Batch, Head, SeqLen, Dims]\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "        \n",
        "        values, attention = scaled_dot_product(q, k, v, mask=mask)\n",
        "        values = values.permute(0, 2, 1, 3) # [Batch, SeqLen, Head, Dims]\n",
        "        values = values.reshape(batch_size, seq_length, embed_dim)\n",
        "        o = self.o_proj(values)\n",
        "        \n",
        "        if return_attention:\n",
        "            return o, attention\n",
        "        else:\n",
        "            return o"
      ],
      "metadata": {
        "id": "RUvXCWZsBoGm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, n_heads, dim_ff, dropout=0.0):\n",
        "\n",
        "        super().__init__()\n",
        "        \n",
        "        # Attention layer\n",
        "        self.self_attn = MultiheadAttention(input_dim, input_dim, n_heads)\n",
        "        \n",
        "        # Two-layer MLP\n",
        "        self.linear_net = nn.Sequential(\n",
        "            nn.Linear(input_dim, dim_ff),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(dim_ff, input_dim)\n",
        "        )\n",
        "        \n",
        "        # Layers to apply in between the main layers\n",
        "        self.norm1 = nn.LayerNorm(input_dim)\n",
        "        self.norm2 = nn.LayerNorm(input_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "\n",
        "        attn_out = self.self_attn(x, mask=mask)\n",
        "        x = x + self.dropout(attn_out)\n",
        "        x = self.norm1(x)\n",
        "        \n",
        "        linear_out = self.linear_net(x)\n",
        "        x = x + self.dropout(linear_out)\n",
        "        x = self.norm2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_layers, **block_args):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([EncoderBlock(**block_args) for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        for l in self.layers:\n",
        "            x = l(x, mask=mask)\n",
        "        return x\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        pos_enc = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pos_enc[:, 0::2] = torch.sin(position * div_term)\n",
        "        pos_enc[:, 1::2] = torch.cos(position * div_term)\n",
        "        pos_enc = pos_enc.unsqueeze(0)\n",
        "        \n",
        "        self.register_buffer('pos_enc', pos_enc, persistent=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pos_enc[:, :x.size(1)]\n",
        "        return x"
      ],
      "metadata": {
        "id": "L1AIoVGrB8a6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbed(nn.Module):\n",
        "\n",
        "    def __init__(self, img_size, patch_size, in_chans, embed_dim):\n",
        "        super().__init__()\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.n_patches = (img_size // patch_size) ** 2\n",
        "\n",
        "\n",
        "        self.proj = nn.Conv2d(\n",
        "                in_chans,\n",
        "                embed_dim,\n",
        "                kernel_size=patch_size,\n",
        "                stride=patch_size,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.proj(\n",
        "                x\n",
        "            )  \n",
        "        x = x.flatten(2)  \n",
        "        x = x.transpose(1, 2)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, dim, n_heads=12, qkv_bias=True, attn_p=0., proj_p=0.):\n",
        "        super().__init__()\n",
        "        self.n_heads = n_heads\n",
        "        self.dim = dim\n",
        "        self.head_dim = dim // n_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_p)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_p)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        n_samples, n_tokens, dim = x.shape\n",
        "\n",
        "        if dim != self.dim:\n",
        "            raise ValueError\n",
        "\n",
        "        qkv = self.qkv(x)  # (n_samples, n_patches + 1, 3 * dim)\n",
        "        qkv = qkv.reshape(\n",
        "                n_samples, n_tokens, 3, self.n_heads, self.head_dim\n",
        "        )  # (n_smaples, n_patches + 1, 3, n_heads, head_dim)\n",
        "        qkv = qkv.permute(\n",
        "                2, 0, 3, 1, 4\n",
        "        )  # (3, n_samples, n_heads, n_patches + 1, head_dim)\n",
        "\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        k_t = k.transpose(-2, -1)  # (n_samples, n_heads, head_dim, n_patches + 1)\n",
        "        dp = (\n",
        "           q @ k_t\n",
        "        ) * self.scale # (n_samples, n_heads, n_patches + 1, n_patches + 1)\n",
        "        attn = dp.softmax(dim=-1)  # (n_samples, n_heads, n_patches + 1, n_patches + 1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        weighted_avg = attn @ v  # (n_samples, n_heads, n_patches +1, head_dim)\n",
        "        weighted_avg = weighted_avg.transpose(\n",
        "                1, 2\n",
        "        )  # (n_samples, n_patches + 1, n_heads, head_dim)\n",
        "        weighted_avg = weighted_avg.flatten(2)  # (n_samples, n_patches + 1, dim)\n",
        "\n",
        "        x = self.proj(weighted_avg)  # (n_samples, n_patches + 1, dim)\n",
        "        x = self.proj_drop(x)  # (n_samples, n_patches + 1, dim)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self, in_features, hidden_features, out_features, p=0.3):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = nn.GELU()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(p)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.fc1(\n",
        "                x\n",
        "        ) # (n_samples, n_patches + 1, hidden_features)\n",
        "        x = self.act(x)  # (n_samples, n_patches + 1, hidden_features)\n",
        "        x = self.drop(x)  # (n_samples, n_patches + 1, hidden_features)\n",
        "        x = self.fc2(x)  # (n_samples, n_patches + 1, out_features)\n",
        "        x = self.drop(x)  # (n_samples, n_patches + 1, out_features)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, dim, n_heads, mlp_ratio=4.0, qkv_bias=True, p=0.3, attn_p=0.):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim, eps=1e-6)\n",
        "        self.attn = Attention(\n",
        "                dim,\n",
        "                n_heads=n_heads,\n",
        "                qkv_bias=qkv_bias,\n",
        "                attn_p=attn_p,\n",
        "                proj_p=p\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(dim, eps=1e-6)\n",
        "        hidden_features = int(dim * mlp_ratio)\n",
        "        self.mlp = MLP(\n",
        "                in_features=dim,\n",
        "                hidden_features=hidden_features,\n",
        "                out_features=dim,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = x + self.attn(self.norm1(x))\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class VisionTransformer(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            img_size,\n",
        "            patch_size,\n",
        "            in_chans,\n",
        "            n_output,\n",
        "            embed_dim,\n",
        "            depth,\n",
        "            n_heads,\n",
        "            mlp_ratio=4.,\n",
        "            qkv_bias=True,\n",
        "            p=0.3,\n",
        "            attn_p=0.3,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.patch_embed = PatchEmbed(\n",
        "                img_size=img_size,\n",
        "                patch_size=patch_size,\n",
        "                in_chans=in_chans,\n",
        "                embed_dim=embed_dim,\n",
        "        )\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.pos_embed = nn.Parameter(\n",
        "                torch.zeros(1, 1 + self.patch_embed.n_patches, embed_dim)\n",
        "        )\n",
        "        self.pos_drop = nn.Dropout(p=p)\n",
        "\n",
        "        self.blocks = nn.ModuleList(\n",
        "            [\n",
        "                Block(\n",
        "                    dim=embed_dim,\n",
        "                    n_heads=n_heads,\n",
        "                    mlp_ratio=mlp_ratio,\n",
        "                    qkv_bias=qkv_bias,\n",
        "                    p=p,\n",
        "                    attn_p=attn_p,\n",
        "                )\n",
        "                for _ in range(depth)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.norm = nn.LayerNorm(embed_dim, eps=1e-6)\n",
        "        self.head = nn.Linear(embed_dim, n_output)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        n_samples = x.shape[0]\n",
        "        x = self.patch_embed(x)\n",
        "\n",
        "        cls_token = self.cls_token.expand(\n",
        "                n_samples, -1, -1\n",
        "        )  # (n_samples, 1, embed_dim)\n",
        "        x = torch.cat((cls_token, x), dim=1)  # (n_samples, 1 + n_patches, embed_dim)\n",
        "        x = x + self.pos_embed  # (n_samples, 1 + n_patches, embed_dim)\n",
        "        x = self.pos_drop(x)\n",
        "\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        x = self.norm(x)\n",
        "\n",
        "        cls_token_final = x[:, 0]\n",
        "        x = self.head(cls_token_final)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "0rMuYZZUqpKe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CosineWarmupScheduler(torch.optim.lr_scheduler._LRScheduler):\n",
        "    \n",
        "    def __init__(self, optimizer, warm_up, max_iters):\n",
        "        self.warm_up = warm_up\n",
        "        self.max_n_iters = max_iters\n",
        "        super().__init__(optimizer)\n",
        "        \n",
        "    def get_lr(self):\n",
        "        lr_factor = self.get_lr_factor(epoch=self.last_epoch)\n",
        "        return [base_lr * lr_factor for base_lr in self.base_lrs]\n",
        "    \n",
        "    def get_lr_factor(self, epoch):\n",
        "        lr_factor = 0.5 * (1 + np.cos(np.pi * epoch / self.max_n_iters))\n",
        "        if epoch <= self.warm_up:\n",
        "            lr_factor *= epoch * 1.0 / self.warm_up\n",
        "        return lr_factor"
      ],
      "metadata": {
        "id": "BI-el1c3COsf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lrvoab8LHsI5"
      },
      "outputs": [],
      "source": [
        "class GazeTransformer(pl.LightningModule):\n",
        "    def __init__(self, \n",
        "                 input_dim_h, \n",
        "                 model_dim_h,\n",
        "                 num_out_h, \n",
        "                 input_dim_s, \n",
        "                 model_dim_s,\n",
        "                 num_out_s, \n",
        "                 n_heads, \n",
        "                 n_layers_h, \n",
        "                 n_layers_s,\n",
        "                 lr, \n",
        "                 seq_length,\n",
        "                 warm_up, \n",
        "                 max_iters,\n",
        "                 criterion, \n",
        "                 dropout=0.0, \n",
        "                 input_dropout=0.0,):\n",
        "        super().__init__()\n",
        "\n",
        "        # model params\n",
        "        self.input_dim_h = input_dim_h\n",
        "        self.model_dim_h =model_dim_h\n",
        "        self.num_out_h = num_out_h\n",
        "        self.input_dim_s = input_dim_s\n",
        "        self.model_dim_s = model_dim_s\n",
        "        self.num_out_s = num_out_s\n",
        "        self.n_heads = n_heads\n",
        "        self.n_layers_h = n_layers_h\n",
        "        self.n_layers_s = n_layers_s\n",
        "        self.lr = lr\n",
        "        self.seq_length = seq_length\n",
        "        self.warm_up = warm_up\n",
        "        self.max_iters = max_iters\n",
        "        self.dropout = dropout\n",
        "        self.input_dropout = input_dropout\n",
        "        self.criterion = criterion\n",
        "\n",
        "        self.seq_size = self.seq_length * self.input_dim_h\n",
        "\n",
        "        prd_fc_linear_size_1 = 128\n",
        "        prd_fc_input_size = self.num_out_s + self.num_out_h\n",
        "\n",
        "        # Encoder for head object sequence\n",
        "        self.input_net_h = nn.Sequential(\n",
        "            nn.Dropout(self.input_dropout),\n",
        "            nn.Linear(self.input_dim_h, self.model_dim_h)\n",
        "        )\n",
        "        # Positional encoding for sequences\n",
        "        self.positional_encoding_h = PositionalEncoding(d_model=self.model_dim_h)\n",
        "        # Transformer\n",
        "        self.transformer_h = TransformerEncoder(n_layers=self.n_layers_h,\n",
        "                                              input_dim=self.model_dim_h,\n",
        "                                              dim_ff=2*self.model_dim_h,\n",
        "                                              n_heads=self.n_heads,\n",
        "                                              dropout=self.dropout)\n",
        "        # Output classifier per sequence lement\n",
        "        self.output_net_h = nn.Sequential(\n",
        "            nn.Linear(self.model_dim_h, self.model_dim_h),\n",
        "            nn.LayerNorm(self.model_dim_h),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.model_dim_h, self.num_out_h)\n",
        "        )\n",
        "\n",
        "\n",
        "        # Encoder for saliency features\n",
        "        self.saliencyTransformer = VisionTransformer(img_size= 24,\n",
        "                                                    in_chans= 2,\n",
        "                                                    patch_size=4,\n",
        "                                                    embed_dim= 32,\n",
        "                                                    depth= self.n_layers_s,\n",
        "                                                    n_heads =8,\n",
        "                                                    qkv_bias= True,\n",
        "                                                    mlp_ratio= 4,\n",
        "                                                    n_output=32)\n",
        "\n",
        "        self.prd_fc = nn.Sequential(\n",
        "            nn.Linear(prd_fc_input_size, prd_fc_linear_size_1),\n",
        "            nn.BatchNorm1d(prd_fc_linear_size_1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p = self.dropout)\n",
        "        )\n",
        "\n",
        "        self.prd_cnn = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=1, out_channels=2,kernel_size=128, padding='valid'),\n",
        "             )\n",
        "        \n",
        "    def forward(self, x, mask=None, add_positional_encoding=True):\n",
        "\n",
        "        head_obj_seq = x[:, 0:self.seq_size]       \n",
        "        sal_features = x[:, self.seq_size:]\n",
        "\n",
        "        head_obj_seq = head_obj_seq.reshape(-1, self.seq_length, self.input_dim_h)\n",
        "\n",
        "        head_obj_seq = self.input_net_h(head_obj_seq)\n",
        "\n",
        "        if add_positional_encoding:\n",
        "            head_obj_seq = self.positional_encoding_h(head_obj_seq)\n",
        "        head_obj_seq = self.transformer_h(head_obj_seq, mask=mask)\n",
        "        head_obj_seq = head_obj_seq[:, -1, :]\n",
        "        head_obj_seq = self.output_net_h(head_obj_seq)\n",
        "\n",
        "        sal_features = sal_features.reshape(-1, 2, 24, 24)\n",
        "\n",
        "        sal_features = self.saliencyTransformer(sal_features)\n",
        "        \n",
        "        batch, _ = sal_features.shape\n",
        "\n",
        "        prd_inp = torch.cat((head_obj_seq, sal_features), 1)\n",
        "\n",
        "        fc_out = self.prd_fc(prd_inp)\n",
        "        fc_out = fc_out.view(batch, 1, -1)\n",
        "        out = self.prd_cnn(fc_out).view(batch, -1)\n",
        "\n",
        "        return out\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "        # Apply lr scheduler per step\n",
        "        lr_scheduler = CosineWarmupScheduler(optimizer, \n",
        "                                             warm_up=self.warm_up, \n",
        "                                             max_iters=self.max_iters)\n",
        "        return [optimizer], [{'scheduler': lr_scheduler, 'interval': 'step'}]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        features, labels = batch\n",
        "\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        output = self(features)\n",
        "\n",
        "        loss = self.criterion(output, labels)\n",
        "\n",
        "        self.log('train_loss', loss)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        features, labels = batch\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        output = self(features)\n",
        "\n",
        "        loss = self.criterion(output, labels)\n",
        "\n",
        "        # Calling self.log will surface up scalars for you in TensorBoard\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        features, labels = batch\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        output = self(features)\n",
        "\n",
        "        loss = self.criterion(output, labels)\n",
        "\n",
        "        prd_error = 0\n",
        "        ver_error = 0\n",
        "        hor_error = 0\n",
        "\n",
        "        for i in range(output.size(0)):\n",
        "            prd_error += CalAngularDist(labels[i, 0:2], output[i, 0:2])\n",
        "            ver_error += abs(labels[i, 0] - output[i, 0])\n",
        "            hor_error += abs(labels[i, 1] - output[i, 1])\n",
        "\n",
        "        mean_ver_error = ver_error / output.size(0)\n",
        "        mean_hor_error = hor_error / output.size(0)\n",
        "        mean_prd_error = prd_error / output.size(0)\n",
        "\n",
        "        pixel_pred = AngularCoord2PixelCoord(output[0])\n",
        "        pixel_gth = AngularCoord2PixelCoord(labels[0])\n",
        "\n",
        "        prd_x.append(pixel_pred[0])\n",
        "        prd_y.append(pixel_pred[1])\n",
        "        gth_x.append(pixel_gth[0])\n",
        "        gth_y.append(pixel_gth[1])\n",
        "\n",
        "        self.log(\"test_loss\", loss, prog_bar=True)\n",
        "        self.log(\"test_ang_error\", mean_prd_error, prog_bar=True)\n",
        "        self.log(\"mean_ver_error\", mean_ver_error, prog_bar=True)\n",
        "        self.log(\"mean_hor_error\", mean_hor_error, prog_bar=True)\n",
        "        return loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "NYEoBygevAc4"
      },
      "outputs": [],
      "source": [
        "def get_args(train=True):\n",
        "    args = dict()\n",
        "    args['seq_length'] = 50\n",
        "    args['seq_feature_num'] = 11\n",
        "    args['sal_feature_num'] = 576\n",
        "    # the dropout rate of the model.\n",
        "    args['dropout_rate'] = 0.5   \n",
        "    args['gradient_clip'] = 0.1  \n",
        "    # the directory that saves the dataset.\n",
        "    args['datasetDir'] = 'DGaze_TrainTest/'\n",
        "    # the number of total epochs to run\n",
        "    args['epochs'] = 30\n",
        "    # the batch size\n",
        "    args['batch_size'] = 64\n",
        "    # the initial learning rate.\n",
        "    args['lr'] = 5e-4\n",
        "    args['model_dim_h'] = 32\n",
        "    args['model_dim_s'] = 32\n",
        "    args['n_heads'] = 8\n",
        "    args['n_layers_h'] = 3\n",
        "    args['n_layers_s'] = 3\n",
        "    args['num_out_h'] = 128\n",
        "    args['num_out_s'] = 32\n",
        "    args['warm_up'] = 2\n",
        "    return args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "s43FWxvFLoAS"
      },
      "outputs": [],
      "source": [
        "def CalAngularDist(gth, prd):\n",
        "\n",
        "\tvertical_fov = math.pi*110/180;\n",
        "\n",
        "\tscreen_w = 1080\n",
        "\tscreen_h = 1200\n",
        "\tscreen_center_x = 0.5*screen_w\n",
        "\tscreen_center_y = 0.5*screen_h\n",
        "\n",
        "\tscreen_dist = 0.5* screen_h/math.tan(vertical_fov/2)\n",
        "\t\n",
        "\n",
        "\tgth = AngularCoord2ScreenCoord(gth)\n",
        "\tprd = AngularCoord2ScreenCoord(prd)\n",
        "\n",
        "\tgth[0] = gth[0]*screen_w\n",
        "\tgth[1] = gth[1]*screen_h\n",
        "\tprd[0] = prd[0]*screen_w\n",
        "\tprd[1] = prd[1]*screen_h\n",
        "\t\n",
        "\t#the distance between eye and gth.\n",
        "\teye2gth = np.sqrt(np.square(screen_dist) + np.square(gth[0] - screen_center_x) + np.square(gth[1] - screen_center_y))\n",
        "\t#the distance between eye and prd.\n",
        "\teye2prd = np.sqrt(np.square(screen_dist) + np.square(prd[0] - screen_center_x) + np.square(prd[1] - screen_center_y))\n",
        "\t#the distance between gth and prd.\n",
        "\tgth2prd = np.sqrt(np.square(prd[0] - gth[0]) + np.square(prd[1] - gth[1]))\n",
        "\t\n",
        "\t#the angular distance between gth and prd.\n",
        "\tangular_dist = 180/math.pi*math.acos((np.square(eye2gth) + np.square(eye2prd) - np.square(gth2prd))/(2*eye2gth*eye2prd))\n",
        "\treturn angular_dist\n",
        "\n",
        "def AngularCoord2PixelCoord(angular_coord):\n",
        "\tscreen_w = 1080\n",
        "\tscreen_h = 1200\n",
        "\n",
        "\tscreen_coord = AngularCoord2ScreenCoord(angular_coord);\n",
        "\n",
        "\tpixel_coord = np.zeros(2)\n",
        "\n",
        "\tpixel_coord[0] = screen_coord[0]*screen_w\n",
        "\tpixel_coord[1] = screen_coord[1]*screen_h\n",
        "\n",
        "\treturn pixel_coord\n",
        "\t\n",
        "def AngularCoord2ScreenCoord(angular_coord):\n",
        "\n",
        "\tvertical_fov = math.pi*110/180\n",
        "\n",
        "\tscreen_w = 1080\n",
        "\tscreen_h = 1200\n",
        "\n",
        "\tscreen_dist = 0.5* screen_h/math.tan(vertical_fov/2)\n",
        "\t\n",
        "\tscreen_coord = np.zeros(2)\n",
        "\n",
        "\tscreen_coord[0] = (screen_dist * math.tan(math.pi*angular_coord[0] / 180) + 0.5*screen_w) / screen_w\n",
        "\n",
        "\tscreen_coord[1] = (screen_dist * math.tan(-math.pi*angular_coord[1] / 180) + 0.5*screen_h) / screen_h\n",
        "\treturn screen_coord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "JVVbRfJku18W"
      },
      "outputs": [],
      "source": [
        "def main(args, train=True):\n",
        "\n",
        "    # Load dataset\n",
        "    train_loader, test_loader, validation_loader = LoadData(args['datasetDir'], args['batch_size'])\n",
        "\n",
        "    # Create the model.\n",
        "    root_dir = os.getcwd()\n",
        "\n",
        "    print('\\n==> Starting...')\n",
        "\n",
        "    csv_logger = CSVLogger('./', name='final', version='3'),\n",
        "\n",
        "\n",
        "    trainer = Trainer(\n",
        "        default_root_dir=root_dir,\n",
        "        max_epochs=args['epochs'],\n",
        "        logger=csv_logger,\n",
        "        gpus=1,\n",
        "        log_every_n_steps=1,\n",
        "        gradient_clip_val=args['gradient_clip'],\n",
        "        progress_bar_refresh_rate=1\n",
        "    )\n",
        "    \n",
        "    model = GazeTransformer(\n",
        "        input_dim_h =args['seq_feature_num'], \n",
        "        model_dim_h=args['model_dim_h'],\n",
        "        num_out_h=args['num_out_h'], \n",
        "        input_dim_s=args['sal_feature_num'], \n",
        "        model_dim_s=args['model_dim_s'],\n",
        "        num_out_s=args['num_out_s'], \n",
        "        seq_length = args['seq_length'],\n",
        "        n_heads= args['n_heads'], \n",
        "        n_layers_h = args['n_layers_h'], \n",
        "        n_layers_s = args['n_layers_s'], \n",
        "        lr= args['lr'], \n",
        "        warm_up= args['warm_up'], \n",
        "        max_iters = args['epochs'],\n",
        "        criterion = nn.L1Loss(), \n",
        "        dropout=args['dropout_rate'], \n",
        "        input_dropout=0.0\n",
        "    )\n",
        "\n",
        "    if train:\n",
        "      print('\\n==> Training...')\n",
        "      trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=validation_loader)\n",
        "\n",
        "      # plot \n",
        "      metrics = pd.read_csv('./final/0/metrics.csv')\n",
        "      train_loss = metrics[['train_loss', 'step', 'epoch']][~np.isnan(metrics['train_loss'])]\n",
        "      val_loss = metrics[['val_loss', 'epoch']][~np.isnan(metrics['val_loss'])]\n",
        "\n",
        "      fig, axes = plt.subplots(1, 2, figsize=(16, 5), dpi=100)\n",
        "      axes[0].set_title('Train loss per batch')\n",
        "      axes[0].plot(train_loss['step'][::2000], train_loss['train_loss'][::2000])\n",
        "      axes[1].set_title('Validation loss per epoch')\n",
        "      axes[1].plot(val_loss['epoch'], val_loss['val_loss'], color='orange')\n",
        "      plt.show(block = True)\n",
        "\n",
        "      print(f\"Train loss: {train_loss['train_loss'].iloc[-1]:.3f}\")\n",
        "      print(f\"Val loss:   {val_loss['val_loss'].iloc[-1]:.3f}\")\n",
        "\n",
        "    else:\n",
        "      print('\\n==> Testing...')\n",
        "      chk_path = \"./final/1/checkpoints/epoch=3-step=65356.ckpt\"\n",
        "      model2 = model.load_from_checkpoint(chk_path,         \n",
        "                                          input_dim_h =args['seq_feature_num'], \n",
        "                                          model_dim_h=args['model_dim_h'],\n",
        "                                          num_out_h=args['num_out_h'], \n",
        "                                          input_dim_s=args['sal_feature_num'], \n",
        "                                          model_dim_s=args['model_dim_s'],\n",
        "                                          num_out_s=args['num_out_s'], \n",
        "                                          n_heads= args['n_heads'], \n",
        "                                          n_layers_h = args['n_layers_h'], \n",
        "                                          n_layers_s = args['n_layers_s'],  \n",
        "                                          lr= args['lr'], \n",
        "                                          seq_length = args['seq_length'],\n",
        "                                          warm_up= args['warm_up'], \n",
        "                                          max_iters = args['epochs'],\n",
        "                                          criterion = nn.L1Loss(), \n",
        "                                          dropout=args['dropout_rate'], \n",
        "                                          input_dropout=0.0)\n",
        "\n",
        "      trainer.test(model=model2, dataloaders=test_loader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plotComparisonGraph(gth_x, gth_y, prd_x, prd_y):\n",
        "  s = [5] * len(prd_x)\n",
        "  plt.figure(figsize=(12,9))\n",
        "\n",
        "  gth = plt.scatter(gth_x, gth_y, s, color = '#88c999')\n",
        "\n",
        "  prd = plt.scatter(prd_x, prd_y, s, color = 'hotpink')\n",
        "  plt.xlim(0, 1080)\n",
        "  plt.ylim(0, 1200)\n",
        "\n",
        "  plt.title(\"Predicted gaze positions versus ground truth\", fontsize=16)\n",
        "\n",
        "  plt.xlabel(\"Horizontal /pixel\", fontsize=16)\n",
        "  plt.ylabel(\"Vertical /pixel\", fontsize=16)\n",
        "\n",
        "  plt.legend((prd, gth),\n",
        "            ('Predicted', 'Ground Truth'),\n",
        "            scatterpoints=1,\n",
        "            loc='lower left',\n",
        "            ncol=3,\n",
        "            fontsize=12)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "455XI0Ro5OE1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dbd1a55b19484f7f9c4ecfa7802fcd78",
            "ad9694af0c8f46b19bde2a38f04bddf7",
            "02f8c10d13b64ea88cf5cb4b5e2302c6",
            "abae7bc1484b4c9b931c6550f77924e6",
            "26900e4bf77b47d8b35a78bdd38bf8df",
            "a3c1d33065964e779f03230aa42ac7cd",
            "6efa5098b8d34802897d55de64e0a1ef",
            "3b79db3d6ed44aa8b4c624419dace814",
            "549437f5d3624136a3e243b1ea224262",
            "cf5ecaeabdb2485b80d49447de0b7f67",
            "35122f409f224ce9a5ec49a8bdaf4ebb",
            "617b182eb98a481386dc35f7d991aff0",
            "6bf886187151442c912b4c7f43bb2daf",
            "f79deaf7d6194fc99a0d0aa641edd9dd",
            "ac1733c51ad74a2dbb063ad99dd227c6",
            "f2f76b2cf1e84480b3dea89815746b9d",
            "347b1cf772a340209bc85c0f092af5f6",
            "ac3d908a97034e328821a463f55453c6",
            "9c78e11a2cd4400c9f8c78133729ee81",
            "b9e296fd472b43f68e5793dbbcac1a07",
            "93df6701a5e2466fb72c620814dffd5e",
            "772fdc157d5a4586916c648ad7bcbe4d"
          ]
        },
        "id": "q8t6cJJklvTW",
        "outputId": "266aca01-d64c-4bfe-8870-05a8610e9283"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Global seed set to 42\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "\n",
            "Loading the training dataset\n",
            "\n",
            "Training Data Size: [1045654, 1702]\n",
            "\n",
            "Loading the testing dataset\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
            "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Data Size: [349152, 1702]\n",
            "\n",
            "Loading the validation dataset\n",
            "\n",
            "Validation Data Size: [349152, 1702]\n",
            "\n",
            "==> Starting...\n",
            "\n",
            "==> Training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory ./final/3/checkpoints exists and is not empty.\n",
            "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name                  | Type               | Params\n",
            "-------------------------------------------------------------\n",
            "0 | criterion             | L1Loss             | 0     \n",
            "1 | input_net_h           | Sequential         | 384   \n",
            "2 | positional_encoding_h | PositionalEncoding | 0     \n",
            "3 | transformer_h         | TransformerEncoder | 25.6 K\n",
            "4 | output_net_h          | Sequential         | 5.3 K \n",
            "5 | saliencyTransformer   | VisionTransformer  | 41.5 K\n",
            "6 | prd_fc                | Sequential         | 20.9 K\n",
            "7 | prd_cnn               | Sequential         | 258   \n",
            "-------------------------------------------------------------\n",
            "94.0 K    Trainable params\n",
            "0         Non-trainable params\n",
            "94.0 K    Total params\n",
            "0.376     Total estimated model params size (MB)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loggers/csv_logs.py:58: UserWarning: Experiment logs directory ./final/3 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
            "  f\"Experiment logs directory {self.log_dir} exists and is not empty.\"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbd1a55b19484f7f9c4ecfa7802fcd78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "617b182eb98a481386dc35f7d991aff0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-339a2ae3d34b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-1055f3330eeb>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args, train)\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0;31m# plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./final/0/metrics.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m       \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['train_loss'] not in index\""
          ]
        }
      ],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# set the random seed to ensure reproducibility\n",
        "seed_everything(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "train = True\n",
        "\n",
        "prd_x = []\n",
        "prd_y = []\n",
        "gth_x = []\n",
        "gth_y = []\n",
        "\n",
        "args = get_args()\n",
        "main(args, train)\n",
        "\n",
        "if not train:\n",
        "  plotComparisonGraph(gth_x, gth_y, prd_x, prd_y)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "FinalModel.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dbd1a55b19484f7f9c4ecfa7802fcd78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad9694af0c8f46b19bde2a38f04bddf7",
              "IPY_MODEL_02f8c10d13b64ea88cf5cb4b5e2302c6",
              "IPY_MODEL_abae7bc1484b4c9b931c6550f77924e6"
            ],
            "layout": "IPY_MODEL_26900e4bf77b47d8b35a78bdd38bf8df"
          }
        },
        "ad9694af0c8f46b19bde2a38f04bddf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3c1d33065964e779f03230aa42ac7cd",
            "placeholder": "​",
            "style": "IPY_MODEL_6efa5098b8d34802897d55de64e0a1ef",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "02f8c10d13b64ea88cf5cb4b5e2302c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b79db3d6ed44aa8b4c624419dace814",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_549437f5d3624136a3e243b1ea224262",
            "value": 2
          }
        },
        "abae7bc1484b4c9b931c6550f77924e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf5ecaeabdb2485b80d49447de0b7f67",
            "placeholder": "​",
            "style": "IPY_MODEL_35122f409f224ce9a5ec49a8bdaf4ebb",
            "value": " 2/2 [00:00&lt;00:00,  4.50it/s]"
          }
        },
        "26900e4bf77b47d8b35a78bdd38bf8df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "a3c1d33065964e779f03230aa42ac7cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6efa5098b8d34802897d55de64e0a1ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b79db3d6ed44aa8b4c624419dace814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "549437f5d3624136a3e243b1ea224262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf5ecaeabdb2485b80d49447de0b7f67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35122f409f224ce9a5ec49a8bdaf4ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "617b182eb98a481386dc35f7d991aff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bf886187151442c912b4c7f43bb2daf",
              "IPY_MODEL_f79deaf7d6194fc99a0d0aa641edd9dd",
              "IPY_MODEL_ac1733c51ad74a2dbb063ad99dd227c6"
            ],
            "layout": "IPY_MODEL_f2f76b2cf1e84480b3dea89815746b9d"
          }
        },
        "6bf886187151442c912b4c7f43bb2daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_347b1cf772a340209bc85c0f092af5f6",
            "placeholder": "​",
            "style": "IPY_MODEL_ac3d908a97034e328821a463f55453c6",
            "value": "Epoch 0:   8%"
          }
        },
        "f79deaf7d6194fc99a0d0aa641edd9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c78e11a2cd4400c9f8c78133729ee81",
            "max": 21795,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9e296fd472b43f68e5793dbbcac1a07",
            "value": 1780
          }
        },
        "ac1733c51ad74a2dbb063ad99dd227c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93df6701a5e2466fb72c620814dffd5e",
            "placeholder": "​",
            "style": "IPY_MODEL_772fdc157d5a4586916c648ad7bcbe4d",
            "value": " 1780/21795 [01:36&lt;18:05, 18.43it/s, loss=5.92, v_num=3]"
          }
        },
        "f2f76b2cf1e84480b3dea89815746b9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "347b1cf772a340209bc85c0f092af5f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac3d908a97034e328821a463f55453c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c78e11a2cd4400c9f8c78133729ee81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9e296fd472b43f68e5793dbbcac1a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93df6701a5e2466fb72c620814dffd5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "772fdc157d5a4586916c648ad7bcbe4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}