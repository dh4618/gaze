{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTu3ksUDe9lk",
        "outputId": "6d3a1fa9-069d-42fd-df7c-f2dcee689caa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N7PQGCULwpB",
        "outputId": "ddca8333-5def-4fb3-f53a-009ace2d0fd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX\n",
        "!pip install --quiet pytorch-lightning>=1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kQA6NX5hKog"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import collections\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer, seed_everything\n",
        "from pytorch_lightning.loggers.csv_logs import CSVLogger\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import sys\n",
        "from tensorboardX import SummaryWriter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "import numpy as np\n",
        "import time\n",
        "import shutil\n",
        "import time\n",
        "import datetime\n",
        "import argparse\n",
        "import os\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "from math import floor\n",
        "from math import ceil\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YzgfkQFIfLmz",
        "outputId": "23161a9a-bc6e-4776-91fb-260dfce132d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/gaze_project'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "os.chdir('/content/gdrive/MyDrive/gaze_project')\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VADlJTHKXM7H"
      },
      "outputs": [],
      "source": [
        "# create dataset\n",
        "class MyDataset(data.Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        feature, target = self.features[index], self.labels[index]\n",
        "        return feature, target\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    \n",
        "# load data.    \n",
        "def LoadData(dataset_dir, batch_size):\n",
        "\n",
        "    print(\"\\nLoading the training dataset\")\n",
        "    trainingX = torch.from_numpy(np.load(dataset_dir + 'trainingX.npy')).float()\n",
        "    trainingY = torch.from_numpy(np.load(dataset_dir + 'trainingY.npy')).float()    \n",
        "    print('\\nTraining Data Size: {}'.format(list(trainingX.size())))\n",
        "\n",
        "    train_dataset = MyDataset(trainingX, trainingY)\n",
        "\n",
        "    train_loader = data.DataLoader(dataset=train_dataset, num_workers=8, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    print(\"\\nLoading the testing dataset\")\n",
        "    testX = torch.from_numpy(np.load(dataset_dir + 'testX.npy')).float()\n",
        "    testY = torch.from_numpy(np.load(dataset_dir + 'testY.npy')).float()\n",
        "\n",
        "    test_size = testX.size()\n",
        "    test_new_size = test_size[0]//2\n",
        "\n",
        "    test_X = testX[0:test_new_size, :]\n",
        "    test_Y = testY[0:test_new_size, :]\n",
        "\n",
        "    print('\\nTest Data Size: {}'.format(list(test_X.size())))\n",
        "    test_dataset = MyDataset(test_X, test_Y)\n",
        "\n",
        "    test_loader = data.DataLoader(dataset=test_dataset, num_workers=8, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    print(\"\\nLoading the validation dataset\")\n",
        "    validationX = testX[test_new_size:, :]\n",
        "    validationY = testY[test_new_size:, :]\n",
        "\n",
        "    print('\\nValidation Data Size: {}'.format(list(validationX.size())))\n",
        "    validation_dataset = MyDataset(validationX, validationY)\n",
        "\n",
        "    validation_loader = data.DataLoader(dataset=validation_dataset, num_workers=8, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader, validation_loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CosineWarmupScheduler(torch.optim.lr_scheduler._LRScheduler):\n",
        "    \n",
        "    def __init__(self, optimizer, warm_up, max_iters):\n",
        "        self.warm_up = warm_up\n",
        "        self.max_n_iters = max_iters\n",
        "        super().__init__(optimizer)\n",
        "        \n",
        "    def get_lr(self):\n",
        "        lr_factor = self.get_lr_factor(epoch=self.last_epoch)\n",
        "        return [base_lr * lr_factor for base_lr in self.base_lrs]\n",
        "    \n",
        "    def get_lr_factor(self, epoch):\n",
        "        lr_factor = 0.5 * (1 + np.cos(np.pi * epoch / self.max_n_iters))\n",
        "        if epoch <= self.warm_up:\n",
        "            lr_factor *= epoch * 1.0 / self.warm_up\n",
        "        return lr_factor"
      ],
      "metadata": {
        "id": "BI-el1c3COsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    d_k = q.size()[-1]\n",
        "    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n",
        "    attn_logits = attn_logits / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n",
        "    attention = F.softmax(attn_logits, dim=-1)\n",
        "    values = torch.matmul(attention, v)\n",
        "    return values, attention\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, embed_dim, n_heads):\n",
        "        super().__init__()\n",
        "        assert embed_dim % n_heads == 0, \"Embedding dimension must be 0 modulo number of heads.\"\n",
        "        \n",
        "        self.embed_dim = embed_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = embed_dim // n_heads\n",
        "        \n",
        "        self.qkv_proj = nn.Linear(input_dim, 3*embed_dim)\n",
        "        self.o_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        \n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.qkv_proj.weight)\n",
        "        self.qkv_proj.bias.data.fill_(0)\n",
        "        nn.init.xavier_uniform_(self.o_proj.weight)\n",
        "        self.o_proj.bias.data.fill_(0)\n",
        "\n",
        "    def forward(self, x, mask=None, return_attention=False):\n",
        "        batch_size, seq_length, embed_dim = x.size()\n",
        "        qkv = self.qkv_proj(x)\n",
        "        \n",
        "        qkv = qkv.reshape(batch_size, seq_length, self.n_heads, 3*self.head_dim)\n",
        "        qkv = qkv.permute(0, 2, 1, 3) # [Batch, Head, SeqLen, Dims]\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "        \n",
        "        values, attention = scaled_dot_product(q, k, v, mask=mask)\n",
        "        values = values.permute(0, 2, 1, 3) # [Batch, SeqLen, Head, Dims]\n",
        "        values = values.reshape(batch_size, seq_length, embed_dim)\n",
        "        o = self.o_proj(values)\n",
        "        \n",
        "        if return_attention:\n",
        "            return o, attention\n",
        "        else:\n",
        "            return o"
      ],
      "metadata": {
        "id": "RUvXCWZsBoGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, n_heads, dim_ff, dropout=0.0):\n",
        "\n",
        "        super().__init__()\n",
        "        \n",
        "        # Attention layer\n",
        "        self.self_attn = MultiheadAttention(input_dim, input_dim, n_heads)\n",
        "        \n",
        "        # Two-layer MLP\n",
        "        self.linear_net = nn.Sequential(\n",
        "            nn.Linear(input_dim, dim_ff),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(dim_ff, input_dim)\n",
        "        )\n",
        "        \n",
        "        # Layers to apply in between the main layers\n",
        "        self.norm1 = nn.LayerNorm(input_dim)\n",
        "        self.norm2 = nn.LayerNorm(input_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "\n",
        "        attn_out = self.self_attn(x, mask=mask)\n",
        "        x = x + self.dropout(attn_out)\n",
        "        x = self.norm1(x)\n",
        "        \n",
        "        linear_out = self.linear_net(x)\n",
        "        x = x + self.dropout(linear_out)\n",
        "        x = self.norm2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_layers, **block_args):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([EncoderBlock(**block_args) for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        for l in self.layers:\n",
        "            x = l(x, mask=mask)\n",
        "        return x\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        pos_enc = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pos_enc[:, 0::2] = torch.sin(position * div_term)\n",
        "        pos_enc[:, 1::2] = torch.cos(position * div_term)\n",
        "        pos_enc = pos_enc.unsqueeze(0)\n",
        "        \n",
        "        self.register_buffer('pos_enc', pos_enc, persistent=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pos_enc[:, :x.size(1)]\n",
        "        return x"
      ],
      "metadata": {
        "id": "L1AIoVGrB8a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrvoab8LHsI5"
      },
      "outputs": [],
      "source": [
        "class HeadObjTransformer(pl.LightningModule):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 model_dim, \n",
        "                 seq_length, \n",
        "                 n_output, \n",
        "                 n_heads, \n",
        "                 n_layers, \n",
        "                 lr, \n",
        "                 warm_up, \n",
        "                 max_iters,\n",
        "                 criterion, \n",
        "                 dropout=0.0, \n",
        "                 input_dropout=0.0,):\n",
        "        super().__init__()\n",
        "\n",
        "        # model params\n",
        "        self.input_dim = input_dim\n",
        "        self.model_dim = model_dim\n",
        "        self.seq_length = seq_length\n",
        "        self.n_output = n_output\n",
        "        self.n_heads = n_heads\n",
        "        self.n_layers = n_layers\n",
        "        self.lr = lr\n",
        "        self.warm_up = warm_up\n",
        "        self.max_iters = max_iters\n",
        "        self.dropout = dropout\n",
        "        self.input_dropout = input_dropout\n",
        "        self.criterion = criterion\n",
        "\n",
        "        self.seq_size = self.seq_length * self.input_dim\n",
        "\n",
        "        self.input_net = nn.Sequential(\n",
        "            nn.Dropout(self.input_dropout),\n",
        "            nn.Linear(self.input_dim, self.model_dim)\n",
        "        )\n",
        "\n",
        "        # Positional encoding \n",
        "        self.positional_encoding = PositionalEncoding(d_model=self.model_dim)\n",
        "\n",
        "        # Transformer\n",
        "        self.transformer = TransformerEncoder(n_layers=self.n_layers,\n",
        "                                              input_dim=self.model_dim,\n",
        "                                              dim_ff=2*self.model_dim,\n",
        "                                              n_heads=self.n_heads,\n",
        "                                              dropout=self.dropout)\n",
        "        \n",
        "        # Output net\n",
        "        self.output_net = nn.Sequential(\n",
        "            nn.Linear(self.model_dim, self.model_dim),\n",
        "            nn.LayerNorm(self.model_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(self.dropout),\n",
        "            nn.Linear(self.model_dim, self.n_output)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x, mask=None, add_positional_encoding=True):\n",
        "\n",
        "        x = self.input_net(x)\n",
        "\n",
        "        if add_positional_encoding:\n",
        "            x = self.positional_encoding(x)\n",
        "\n",
        "        x = self.transformer(x, mask=mask)\n",
        "        x = self.output_net(x)\n",
        "\n",
        "        return x\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "        # Apply lr scheduler per step\n",
        "        lr_scheduler = CosineWarmupScheduler(optimizer, \n",
        "                                             warm_up=self.warm_up, \n",
        "                                             max_iters=self.max_iters)\n",
        "        return [optimizer], [{'scheduler': lr_scheduler, 'interval': 'step'}]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        features, labels = batch\n",
        "\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        features = features[:, 0:self.seq_size]\n",
        "\n",
        "        features = features.reshape(-1, self.seq_length, self.input_dim)\n",
        "\n",
        "        output = self(features)\n",
        "        output = output[:, -1, :]\n",
        "        loss = self.criterion(output, labels)\n",
        "\n",
        "        self.log('train_loss', loss)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        features, labels = batch\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        features = features[:, 0:self.seq_size]\n",
        "\n",
        "        features = features.reshape(-1, self.seq_length, self.input_dim)\n",
        "\n",
        "        output = self(features)\n",
        "\n",
        "        output = output[:, -1, :]\n",
        "        loss = self.criterion(output, labels)\n",
        "\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "\n",
        "        features, labels = batch\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        features = features[:, 0:self.seq_size]\n",
        "\n",
        "        features = features.reshape(-1, self.seq_length, self.input_dim)\n",
        "\n",
        "        startTime = datetime.datetime.now()\n",
        "        output = self(features)\n",
        "        output = output[:, -1, :]\n",
        "        loss = self.criterion(output, labels)\n",
        "\n",
        "        prd_error = 0\n",
        "        ver_error = 0\n",
        "        hor_error = 0\n",
        "\n",
        "        for i in range(output.size(0)):\n",
        "            prd_error += CalAngularDist(labels[i, 0:2], output[i, 0:2])\n",
        "            ver_error += abs(labels[i, 0] - output[i, 0])\n",
        "            hor_error += abs(labels[i, 1] - output[i, 1])\n",
        "\n",
        "        mean_ver_error = ver_error / output.size(0)\n",
        "        mean_hor_error = hor_error / output.size(0)\n",
        "        mean_prd_error = prd_error / output.size(0)\n",
        "\n",
        "        pixel_pred = AngularCoord2PixelCoord(output[0])\n",
        "        pixel_gth = AngularCoord2PixelCoord(labels[0])\n",
        "\n",
        "        prd_x.append(pixel_pred[0])\n",
        "        prd_y.append(pixel_pred[1])\n",
        "        gth_x.append(pixel_gth[0])\n",
        "        gth_y.append(pixel_gth[1])\n",
        "\n",
        "        self.log(\"test_loss\", loss, prog_bar=True)\n",
        "        self.log(\"test_ang_error\", mean_prd_error, prog_bar=True)\n",
        "        self.log(\"mean_ver_error\", mean_ver_error, prog_bar=True)\n",
        "        self.log(\"mean_hor_error\", mean_hor_error, prog_bar=True)\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYEoBygevAc4"
      },
      "outputs": [],
      "source": [
        "def get_args(train=True):\n",
        "    args = dict()\n",
        "    args['feature_num'] = 1702\n",
        "    args['seq_length'] = 50\n",
        "    args['seq_feature_num'] = 11\n",
        "    # the dropout rate of the model.\n",
        "    args['dropout_rate'] = 0.5   \n",
        "    args['gradient_clip'] = 0.1  \n",
        "    # the directory that saves the dataset.\n",
        "    args['dataset_dir'] = 'DGaze_TrainTest/'\n",
        "    # the number of total epochs to run\n",
        "    args['epochs'] = 30\n",
        "    # the batch size\n",
        "    args['batch_size'] = 64\n",
        "    # the interval that we save the checkpoint\n",
        "    args['interval'] = 10\n",
        "    # the initial learning rate.\n",
        "    args['lr'] = 5e-4\n",
        "    args['model_dim'] = 32\n",
        "    args['n_heads'] = 8\n",
        "    args['n_layers'] = 3\n",
        "    args['warm_up'] = 2\n",
        "    return args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s43FWxvFLoAS"
      },
      "outputs": [],
      "source": [
        "def CalAngularDist(gth, prd):\n",
        "\n",
        "\tvertical_fov = math.pi*110/180;\n",
        "\n",
        "\tscreen_w = 1080\n",
        "\tscreen_h = 1200\n",
        "\tscreen_center_x = 0.5*screen_w\n",
        "\tscreen_center_y = 0.5*screen_h\n",
        "\n",
        "\tscreen_dist = 0.5* screen_h/math.tan(vertical_fov/2)\n",
        "\t\n",
        "\n",
        "\tgth = AngularCoord2ScreenCoord(gth)\n",
        "\tprd = AngularCoord2ScreenCoord(prd)\n",
        "\n",
        "\tgth[0] = gth[0]*screen_w\n",
        "\tgth[1] = gth[1]*screen_h\n",
        "\tprd[0] = prd[0]*screen_w\n",
        "\tprd[1] = prd[1]*screen_h\n",
        "\t\n",
        "\t#the distance between eye and gth.\n",
        "\teye2gth = np.sqrt(np.square(screen_dist) + np.square(gth[0] - screen_center_x) + np.square(gth[1] - screen_center_y))\n",
        "\t#the distance between eye and prd.\n",
        "\teye2prd = np.sqrt(np.square(screen_dist) + np.square(prd[0] - screen_center_x) + np.square(prd[1] - screen_center_y))\n",
        "\t#the distance between gth and prd.\n",
        "\tgth2prd = np.sqrt(np.square(prd[0] - gth[0]) + np.square(prd[1] - gth[1]))\n",
        "\t\n",
        "\t#the angular distance between gth and prd.\n",
        "\tangular_dist = 180/math.pi*math.acos((np.square(eye2gth) + np.square(eye2prd) - np.square(gth2prd))/(2*eye2gth*eye2prd))\n",
        "\treturn angular_dist\n",
        "\n",
        "def AngularCoord2PixelCoord(angular_coord):\n",
        "\tscreen_w = 1080\n",
        "\tscreen_h = 1200\n",
        "\n",
        "\tscreen_coord = AngularCoord2ScreenCoord(angular_coord);\n",
        "\n",
        "\tpixel_coord = np.zeros(2)\n",
        "\n",
        "\tpixel_coord[0] = screen_coord[0]*screen_w\n",
        "\tpixel_coord[1] = screen_coord[1]*screen_h\n",
        "\n",
        "\treturn pixel_coord\n",
        "\t\n",
        "def AngularCoord2ScreenCoord(angular_coord):\n",
        "\n",
        "\tvertical_fov = math.pi*110/180\n",
        "\n",
        "\tscreen_w = 1080\n",
        "\tscreen_h = 1200\n",
        "\n",
        "\tscreen_dist = 0.5* screen_h/math.tan(vertical_fov/2)\n",
        "\t\n",
        "\tscreen_coord = np.zeros(2)\n",
        "\n",
        "\tscreen_coord[0] = (screen_dist * math.tan(math.pi*angular_coord[0] / 180) + 0.5*screen_w) / screen_w\n",
        "\n",
        "\tscreen_coord[1] = (screen_dist * math.tan(-math.pi*angular_coord[1] / 180) + 0.5*screen_h) / screen_h\n",
        "\treturn screen_coord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVVbRfJku18W"
      },
      "outputs": [],
      "source": [
        "def main(args, train=True):\n",
        "    \n",
        "    # Load dataset\n",
        "    train_loader, test_loader, validation_loader = LoadData(args['dataset_dir'], args['batch_size'])\n",
        "\n",
        "    # Create the model.\n",
        "    root_dir = os.getcwd()\n",
        "\n",
        "    print('\\n==> Starting...')\n",
        "\n",
        "    csv_logger = CSVLogger('./', name='head_transformer', version='2'),\n",
        "\n",
        "    trainer = Trainer(\n",
        "        default_root_dir=root_dir,\n",
        "        max_epochs=args['epochs'],\n",
        "        logger=csv_logger,\n",
        "        gpus=1,\n",
        "        log_every_n_steps=1,\n",
        "        gradient_clip_val=args['gradient_clip'],\n",
        "        progress_bar_refresh_rate=1\n",
        "    )\n",
        "    \n",
        "    model = HeadObjTransformer(\n",
        "        input_dim = args['seq_feature_num'],\n",
        "        model_dim = args['model_dim'], \n",
        "        n_output = 2, \n",
        "        n_heads = args['n_heads'], \n",
        "        n_layers = args['n_layers'], \n",
        "        lr = args['lr'], \n",
        "        seq_length = args['seq_length'],\n",
        "        warm_up = args['warm_up'], \n",
        "        max_iters = args['epochs'], \n",
        "        dropout=args['dropout_rate'], \n",
        "        input_dropout=0.0,\n",
        "        criterion = nn.L1Loss()\n",
        "    )\n",
        "\n",
        "    if train:\n",
        "      print('\\n==> Training...')\n",
        "      trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=validation_loader)\n",
        "\n",
        "      metrics = pd.read_csv('./head_transformer/1/metrics.csv')\n",
        "      train_loss = metrics[['train_loss', 'step', 'epoch']][~np.isnan(metrics['train_loss'])]\n",
        "      val_loss = metrics[['val_loss', 'epoch']][~np.isnan(metrics['val_loss'])]\n",
        "\n",
        "      fig, axes = plt.subplots(1, 2, figsize=(16, 5), dpi=100)\n",
        "      axes[0].set_title('Train loss per batch')\n",
        "      axes[0].plot(train_loss['step'][::2000], train_loss['train_loss'][::2000])\n",
        "      axes[1].set_title('Validation loss per epoch')\n",
        "      axes[1].plot(val_loss['epoch'], val_loss['val_loss'], color='orange')\n",
        "      plt.show(block = True)\n",
        "\n",
        "      print(f\"Train loss: {train_loss['train_loss'].iloc[-1]:.3f}\")\n",
        "      print(f\"Val loss:   {val_loss['val_loss'].iloc[-1]:.3f}\")\n",
        "\n",
        "    else:\n",
        "      print('\\n==> Testing...')\n",
        "      chk_path = \"./head_transformer/1/checkpoints/epoch=6-step=114373.ckpt\"\n",
        "      model2 = model.load_from_checkpoint(chk_path,         \n",
        "                                          input_dim = args['seq_feature_num'],\n",
        "                                          model_dim = args['model_dim'], \n",
        "                                          n_output = 2, \n",
        "                                          n_heads = args['n_heads'], \n",
        "                                          n_layers = args['n_layers'], \n",
        "                                          lr = args['lr'], \n",
        "                                          seq_length = args['seq_length'],\n",
        "                                          warm_up = args['warm_up'], \n",
        "                                          max_iters = args['epochs'], \n",
        "                                          dropout=args['dropout_rate'], \n",
        "                                          input_dropout=0.0,\n",
        "                                          criterion = nn.L1Loss())\n",
        "      trainer.test(model=model2, dataloaders=test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plotComparisonGraph(gth_x, gth_y, prd_x, prd_y):\n",
        "  s = [5] * len(prd_x)\n",
        "  plt.figure(figsize=(12,9))\n",
        "\n",
        "  gth = plt.scatter(gth_x, gth_y, s, color = '#88c999')\n",
        "\n",
        "  prd = plt.scatter(prd_x, prd_y, s, color = 'hotpink')\n",
        "  plt.xlim(0, 1080)\n",
        "  plt.ylim(0, 1200)\n",
        "\n",
        "  plt.title(\"Predicted gaze positions versus ground truth\", fontsize=16)\n",
        "\n",
        "  plt.xlabel(\"Horizontal /pixel\", fontsize=16)\n",
        "  plt.ylabel(\"Vertical /pixel\", fontsize=16)\n",
        "\n",
        "  plt.legend((prd, gth),\n",
        "            ('Predicted', 'Ground Truth'),\n",
        "            scatterpoints=1,\n",
        "            loc='lower left',\n",
        "            ncol=3,\n",
        "            fontsize=12)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "3zqFMOuJfrxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659,
          "referenced_widgets": [
            "5cde2e9a3c344841ac61c4407712669c",
            "436c5d26a74548518799ec79ecc6c507",
            "c035a9f73e6442dabde4268e0014bc43",
            "6b9b4e98ceb54438a56887532d5fee40",
            "c1f4e7ca85004f388b3582a768cd6fcc",
            "0d2c54088204437182a108d18d20f80d",
            "e659579738ba4b76a0ed7a8ec3c96962",
            "a00cb7830dd4494aae9d33d7093efa21",
            "9d00cf67eb98498284fbf8e9a4c3f111",
            "40f81f1a628445298565307cd5b3b2e4",
            "348f338f00f34f0b80e311c429c7c53b"
          ]
        },
        "id": "q8t6cJJklvTW",
        "outputId": "5bf79a2b-f311-4ed2-dc97-220adfe9165e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "\n",
            "Loading the training data...\n",
            "\n",
            "Training Data Size: [1045654, 1702]\n",
            "\n",
            "Loading the test data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=1)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
            "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Data Size: [349152, 1702]\n",
            "\n",
            "Loading the validation data...\n",
            "\n",
            "Validation Data Size: [349152, 1702]\n",
            "\n",
            "==> Creating the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loggers/csv_logs.py:58: UserWarning: Experiment logs directory ./head_transformer/1 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
            "  f\"Experiment logs directory {self.log_dir} exists and is not empty.\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5cde2e9a3c344841ac61c4407712669c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "       Test metric             DataLoader 0\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
            "     mean_hor_error          4.669387340545654\n",
            "     mean_ver_error          4.91747522354126\n",
            "     test_ang_error          7.428003311157227\n",
            "   test_avg_pred_time               0.0\n",
            "        test_loss            4.793443202972412\n",
            "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
          ]
        }
      ],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# set the random seed to ensure reproducibility\n",
        "seed_everything(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "train = True\n",
        "\n",
        "prd_x = []\n",
        "prd_y = []\n",
        "gth_x = []\n",
        "gth_y = []\n",
        "\n",
        "args = get_args()\n",
        "main(args, train)\n",
        "\n",
        "if not train:\n",
        "  plotComparisonGraph(gth_x, gth_y, prd_x, prd_y)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "HeadObjTransformer.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5cde2e9a3c344841ac61c4407712669c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_436c5d26a74548518799ec79ecc6c507",
              "IPY_MODEL_c035a9f73e6442dabde4268e0014bc43",
              "IPY_MODEL_6b9b4e98ceb54438a56887532d5fee40"
            ],
            "layout": "IPY_MODEL_c1f4e7ca85004f388b3582a768cd6fcc"
          }
        },
        "436c5d26a74548518799ec79ecc6c507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d2c54088204437182a108d18d20f80d",
            "placeholder": "​",
            "style": "IPY_MODEL_e659579738ba4b76a0ed7a8ec3c96962",
            "value": "Testing DataLoader 0: 100%"
          }
        },
        "c035a9f73e6442dabde4268e0014bc43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a00cb7830dd4494aae9d33d7093efa21",
            "max": 5456,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d00cf67eb98498284fbf8e9a4c3f111",
            "value": 5456
          }
        },
        "6b9b4e98ceb54438a56887532d5fee40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40f81f1a628445298565307cd5b3b2e4",
            "placeholder": "​",
            "style": "IPY_MODEL_348f338f00f34f0b80e311c429c7c53b",
            "value": " 5456/5456 [02:24&lt;00:00, 37.99it/s]"
          }
        },
        "c1f4e7ca85004f388b3582a768cd6fcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "0d2c54088204437182a108d18d20f80d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e659579738ba4b76a0ed7a8ec3c96962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a00cb7830dd4494aae9d33d7093efa21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d00cf67eb98498284fbf8e9a4c3f111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40f81f1a628445298565307cd5b3b2e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "348f338f00f34f0b80e311c429c7c53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}